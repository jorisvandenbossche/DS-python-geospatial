{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=\"6\"><b>Numpy</b></font></p>\n",
    "\n",
    "\n",
    "> *DS Python for GIS and Geoscience*  \n",
    "> *September, 2024*\n",
    ">\n",
    "> *Â© 2024, Joris Van den Bossche and Stijn Van Hoey. Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "from rasterio.plot import plotting_extent, show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __In this notebook, the usage of Numpy when working with spatial data is explained and some exercises from xarray are solved using Numpy directly.__\n",
    "\n",
    "On of the most fundamental parts of the scientific python 'ecosystem' is [numpy](https://numpy.org/). A lot of other packages - you use Pandas, GeoPandas and xarray in this course - are built on top of Numpy and the `ndarray`  (n-dimensional array) data type it provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from reading in a GeoTiff data set from file, this time a Sentinal Band 4 of the City of Ghent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_b4_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "ax = xr_b4_data.plot(robust=True, figsize=(10, 4))\n",
    "ax.axes.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading in data, xarray contains a Numpy `ndarray` inside the xarray DataArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "type(xr_b4_data), type(xr_b4_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continu with the Numpy ndarray (ignore the additional coordinate and metadata information from xarray):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data = xr_b4_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy supports different `dtype`s (`float`, `int`,...), but all elements of an array do have the same dtype. Note that NumPy auto-detects the data-type from the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of this specific array `b4_data.data` is 16bit unsigned integer. More information on the data types Numpy supports is available in the [documentation](https://numpy.org/devdocs/user/basics.types.html#array-types-and-conversions-between-types). Detailed info on data types is out of scope of this course, but remember that using 16bit unsigned integer, it can contain `2**16` different (all positive) integer values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "2**16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this by calculating the minimum and maximum value in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data.min(), b4_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to another data type is supported by `astype` method. When floats are preferred during calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as any other object in Python, the `ndarray` has a number of attributes. We already checkes the `dtype` attribute. The `shape` and `ndim` of the array are other relevant attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data.shape, b4_data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we have a single band with dimensions (317, 625) and data type `uint16`. Compare this to the metadata stored in the geotiff file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdalinfo ./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata on the dimensions and the datatype correspond, but the spatial information is lost when we only store the Numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy works very well together with the other fundamental scientific Python package [Matplotlib](https://matplotlib.org/). An useful plot function to know when working with raster data is `imshow`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(b4_data.squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Numpy function `squeeze` used to get rid of the single-value dimension of the numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Numpy array does not contain any spatial information, the x and y axis labels are defined by the indices of the array. Remark that the xarray plot returned this plot with the coordinate information in the axis labels. \n",
    "\n",
    "With a small trick, the same result can be achieved with Matplotlib:\n",
    "\n",
    "1. When reading in a data set using xarray, get the spatial extent from the geographical boundaries stored in the xarray `rio` accessor and convert them to an extent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_b4_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", engine=\"rasterio\", mask_and_scale=False)\n",
    "\n",
    "(left, bottom, right, top) = xr_b4_data.rio.bounds()  # get boundary information\n",
    "b4_data_extent = (left, right, bottom, top)   # convert boundaries to extent info\n",
    "b4_data_extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add the `extent` argument to the `imshow` plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(b4_data.squeeze(), extent=b4_data_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "\n",
    "**REMEMBER**: <br>\n",
    "\n",
    "The [`numpy` package](https://numpy.org/) is the backbone of the scientific Python ecosystem. The `ndarray` provides an efficient data type to store and manipulate raster data, but it does NOT contain any spatial information.\n",
    "    \n",
    "Use the spatial `extent` trick to add coordinate information to imshow plot axis. Convert to the preferred datatype using `astype()` method.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape, slice and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already used `squeeze` to remove the single-value dimension. We could also select the data we needed, similar to slicing in lists or Pandas DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4 = b4_data[0]\n",
    "b4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not like the order of dimensions of the data, you can switch these using `transpose`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4.transpose(1, 0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of the dimensions and flattening all values into a single 1-D array can be done using `flatten` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4.flatten().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening an arrya is useful to create a histogram with Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(b4.flatten(), bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice, subsample, reverse\n",
    "# slice + assign\n",
    "# fancy indexing\n",
    "# fancy indexing + assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4 = b4_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a specific row/column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4[:, -2:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select every nth element in a given dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4[100:200:10, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reversing an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4[:, ::-1].shape  # Note you can also np.flip an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4[0, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4_rev = b4[:, ::-1]\n",
    "b4_rev[0, -4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also combine assignment and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4[0, :3] = 10\n",
    "b4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a __condition__ to select data, also called fancy indexing or boolean indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4 < 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onle keep the data which are True for the given condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4[b4 < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or combine assignment and fancy indexing, e.g. a reclassification of the raster data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4[b4 < 5000] = 0  # assign the value 0 to all elements with a value lower than 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "b4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A powerfull shortcut to handle this kind or reclassifications is the `np.where` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.where(b4 < 5000, 10, b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "* Read in the file `./data/gent/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff` with xarray, extract the data as a Numpy ndarray and assign the data to a new variable `tc_data`.  \n",
    "* Select only the *second* layer of `tc_data` and assign the output to a new variable `tc_g`.\n",
    "* Assign to each of the elements in the `tc_g` array with a value above 15000 the new value 65535.\n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* You can combine the assignment of new values together with fancy indexing of a numpy array.\n",
    "* Python (and also Numpy) uses 0 as the first-element index\n",
    "\n",
    "</details>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "xr_tc_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff\", \n",
    "                            engine=\"rasterio\", mask_and_scale=False)\n",
    "tc_data = xr_tc_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the green channel\n",
    "tc_g = tc_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert all values above 15000\n",
    "tc_g[tc_g > 15000] = 65535\n",
    "tc_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "Subsample the ndarray `tc_data` by taking only the one out of each 5 data points for all layers at the same time (Be aware that this is a naive resampling implementation for educational purposes only). \n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* The result should still be a 3-D array with 3 elements in the first dimension.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "xr_tc_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "tc_data = xr_tc_data.data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# subsample the data\n",
    "tc_data[:, ::5, ::5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "Elements with the value `65535` do represent 'Not a Number' (NaN) values. However, Numpy does not support NaN values for integer data, so we'll convert to float first as data type. After reading in the data set `./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff` (assign data to variable `b4_data`):\n",
    "    \n",
    "* Count the number of elements that are equal to `65535`\n",
    "* Convert the data type to `float`, assign the result to  a new variable `b4_data_f`\n",
    "* Assign Nan (`np.nan`) value to each of the elements of `b4_data_f` equal to `65535`\n",
    "* Count the number of Nan values in the `b4_data_f` data\n",
    "* Make a histogram of both the `b4_data` and `b4_data_f` data. Can you spot the difference?\n",
    "    \n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* `np.nan` represents _Not a Number (NaN)_ in Numpy. You can assign an element to it, e.g. `dummy[2] = np.nan`\n",
    "* `np.sum` will by default sum all of the elements of the input array and can also count boolean values (True = 1 and False = 0), resulting from a conditional expression. \n",
    "* To test if a value is a nan, Numpy provides `np.isnan(...)` which results in an element-wise check returning boolean values.\n",
    "* Check the help of the `plt.hist` command to find out more about the `bins` and the `log` arguments.\n",
    "\n",
    "</details>    \n",
    "    \n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "xr_b4_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "b4_data = xr_b4_data.data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Count the number of cells with value 65535\n",
    "np.sum(b4_data == 65535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert to float and make 65535 equal to Nan\n",
    "b4_data_f = b4_data.astype(float)\n",
    "b4_data_f[b4_data == 65535] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Count the number of cells with value 0\n",
    "np.sum(np.isnan(b4_data_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the histogram plots\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "ax0.hist(b4_data.flatten(), bins=30, log=True);\n",
    "ax1.hist(b4_data_f.flatten(), bins=30, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions, element-wise calculations and broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we worked with the 16bit integer values. For specific applications we might want to rescale this data. A (fake) example is the linear transformation to the range 0-1 after log conversion of the data. To do so, we need to calculate _for each element_ in the original $b$ array the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_i= \\log(b_i)$$\n",
    "$$z_i=\\frac{x_i-\\min(x)}{\\max(x)-\\min(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. reductions__\n",
    "\n",
    "As part of it, we need the minimum `min(x)` and the maximum `max(x)` of the array. These __reductions__ (aggregations) are provided by Numpy and can be applied along one or more of the data dimensions, called the __axis__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy = np.arange(1, 10).reshape(3, 3)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.min(dummy), np.min(dummy, axis=0), np.min(dummy, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy = np.arange(1, 25).reshape(2, 3, 4)\n",
    "dummy.shape, dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.min(dummy), np.min(dummy, axis=0), np.min(dummy, axis=(0, 1)), np.min(dummy, axis=(0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some applications, the usage of the `keepdims=True` is useful to keep the number of dimensions after reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.min(dummy, axis=(0, 2), keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with Nan values, the result will be Nan as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.min(np.array([1., 2., np.nan]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `nanmin`, `nan...` version of the function instead, if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.nanmin(np.array([1., 2., np.nan]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Element-wise__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __for each element__ is crucial for Numpy. The typical answer in programming would be a `for`-loop, but Numpy is optimized to do these calculations __element-wise__ (i.e. for all elements together):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy = np.arange(1, 10)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "[el*20 for el in dummy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy provides most of the familiar arithmetic operators to apply on an element-by-element basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.exp(dummy), np.sin(dummy), dummy**2, np.log(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some function, you can either use the `np.min(my_array)` or the `my_array.min()` approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy.min() == np.min(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Broadcasting__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we combine arrays with different shapes during arithmetic operations, Numpy applies a set of __broadcoasting__ rules and the smaller array is _broadcast_ across the larger array so that they have compatible shapes. An important consequence for out application is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.array([1, 2, 3]) + 4. , np.array([1, 2, 3]) + np.array([4.]), np.array([1, 2, 3]) + np.array([4., 4., 4.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest array is broadcasted to make both compatible. It starts with the trailing (i.e. rightmost) dimensions. Exploring all the rules are out of scope in this lesson and are well explained in the [broadcasting Numpy documentation](https://numpy.org/devdocs/user/basics.broadcasting.html#general-broadcasting-rules)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Back to our function__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By combining these three elements, we know enough to translate our conversion into Numpy code on the example data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_b4_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "b4_data = xr_b4_data.data\n",
    "\n",
    "b4_data = b4_data.squeeze().astype(float)    # squeeze and convert to float\n",
    "b4_data[b4_data == 0.0] = 0.00001  # to overcome zero-division error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the log of al the values __element-wise__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_data_log = np.log(b4_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the min and max __reductions__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_min, b4_max = b4_data_log.min(), b4_data_log.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Broadcast__ our single value `b4_min` and `b4_max` to all elements of `b4_data_log`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_rescaled = ((b4_data_log - b4_min)/(b4_max - b4_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(b4_rescaled.flatten(), bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark 1:__ One-dimensional linear interpolation towards a new value range can be calculated using the `np.interp` function as well. For the range 0 -> 1: \n",
    "\n",
    "```\n",
    "np.interp(b4_data, (b4_data.min(), b4_data.max()), (0, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark 2: Why not iterate over the values of a list?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the  rescaling example to compare the calculation with Numpy versus a list comprehension (for-loop in Python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_min, b4_max = b4_data.min(), b4_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rescaled_values_1 = ((b4_data - b4_min)/(b4_max - b4_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a list with a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_as_list = b4_data.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rescaled_values_2 = [((data_point - b4_min)/(b4_max - b4_min)) for data_point in b4_as_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.allclose(rescaled_values_1.flatten(), rescaled_values_2)  # np.allclose also works element wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "\n",
    "**REMEMBER**: <br>\n",
    "\n",
    "The combination of element-wise calculations, efficient reductions and broadcasting provides Numpy a lot of power. In general, it is a good advice to __avoid for loops__ when working with Numpy arrays.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "The data set `./data/herstappe/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff` (assign to variable `herstappe_data`) contains 3 bands. The `imshow` function of Matplotlib can plot 3-D (RGB) data sets, but when running `plt.imshow(herstappe_data)`, we got the following error:\n",
    "    \n",
    "    ```\n",
    "    ...\n",
    "    TypeError: Invalid shape (3, 227, 447) for image data\n",
    "    ```\n",
    "\n",
    "- Check in the help op `plt.imshow` why the `herstappe_data` can not be plot as such\n",
    "- Adjust the data to fix the behavior of `plt.imshow(herstappe_data)`\n",
    "    \n",
    "Next, plot a greyscale version of the data as well. Instead of using a custom function just rely on the sum of the 3 bands as a proxy.\n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* In a Jupyter Notebook, us the SHIFT-TAB combination when the cursor is on the `imshow` function or type in a new cell `?plt.imshow` to see the documentation of a function.\n",
    "* The `imshow` function requires the different color bands as last dimension, so we will need to transpose the image array.\n",
    "* Add the extent to see the coordinates in the axis labels.\n",
    "* A greyscale image requires a greyscale `cmap`, checkt he available names in [the documentation online](https://matplotlib.org/tutorials/colors/colormaps.html)\n",
    "\n",
    "</details>    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "xr_herstappe_data = xr.open_dataarray(\"./data/herstappe/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff\", \n",
    "                                      engine=\"rasterio\", mask_and_scale=False)\n",
    "herstappe_data = xr_herstappe_data.data\n",
    "\n",
    "(left, bottom, right, top) = xr_herstappe_data.rio.bounds()\n",
    "herstappe_extent = (left, right, bottom, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Make a RGB plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.imshow(herstappe_data.transpose(1, 2, 0), extent=herstappe_extent);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Make a Grey scale plot\n",
    "greyscale_data = herstappe_data.sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.imshow(greyscale_data, extent=herstappe_extent, cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "The data set `./data/herstappe/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff` (assign to variable `herstappe_data`) has values ranging in between 0.11325, 0.8575. To improve the quality of the visualization, stretch __each of the layers individually__ to the values to the range 0. to 1. with a linear transformation: \n",
    "    \n",
    "$$z_i=\\frac{x_i-\\min(x)}{\\max(x)-\\min(x)}$$\n",
    "\n",
    "Make a plot of the end result and compare with the plots of the previous exercise. \n",
    "   \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* Keep into account that the data set is 3-dimensional. Have a look at the optional arguments for the reduction/aggregation functions in terms of `axis` and `keepdims`. \n",
    "* You need the minimal/maximal value over 2 axis to end up with a min/max for each of the layers.\n",
    "* Broadcasting starts comparison of the alignment on the last dimension.\n",
    "\n",
    "</details>    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": false
   },
   "outputs": [],
   "source": [
    "xr_herstappe_data = xr.open_dataarray(\"./data/herstappe/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff\", \n",
    "                                      engine=\"rasterio\", mask_and_scale=False)\n",
    "herstappe_data = xr_herstappe_data.data\n",
    "\n",
    "# Get extent\n",
    "(left, bottom, right, top) = xr_herstappe_data.rio.bounds()\n",
    "herstappe_extent = (left, right, bottom, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the min and max for each channel\n",
    "h_min = herstappe_data.min(axis=(1, 2), keepdims=True)\n",
    "h_max = herstappe_data.max(axis=(1, 2), keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Rescale the data\n",
    "herstappe_rescaled = ((herstappe_data - h_min)/(h_max - h_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Make a plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.imshow(herstappe_rescaled.transpose(1, 2, 0), extent=herstappe_extent);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**:\n",
    "    \n",
    "You want to reclassify the values of the 4th band data to a fixed set of classes:\n",
    "    \n",
    "* x < 0.05 need to be 10\n",
    "* 0.05 < x < 0.1 need to be 20\n",
    "* x > 0.1 need to be 30\n",
    "       \n",
    "Use the data set `./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff` (assign data to variable `b4_data`):\n",
    "    \n",
    "* Read the data set and exclude the single-value dimension to end up with a 2D array. \n",
    "* Convert to float data type. and normalize the values to the range [0., 1.].\n",
    "* Create a new variable `b4_data_classified` with the same shape as `b4_data` but datatype int.\n",
    "* Assign the new values (10, 20, 30) to the elements for which each of the conditions apply. \n",
    "* Make a image plot of the reclassified variable `b4_data_classified`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "clear_cell": false
   },
   "outputs": [],
   "source": [
    "xr_b4_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "b4_data = xr_b4_data.data\n",
    "\n",
    "# Get extent\n",
    "(left, bottom, right, top) = xr_b4_data.rio.bounds()\n",
    "b4_data_extent = (left, right, bottom, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Squeeze to 2D float array \n",
    "b4_data = b4_data.squeeze().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Rescale the data\n",
    "b4_data = (b4_data - b4_data.min())/(b4_data.max() - b4_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a new array with the same shape as the original b4_data\n",
    "b4_data_classified = np.empty_like(b4_data).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Assign the new values according to the classes\n",
    "b4_data_classified[b4_data < 0.05] = 10\n",
    "b4_data_classified[(0.05 <= b4_data) & (b4_data < 0.1)] = 20\n",
    "b4_data_classified[0.1 <= b4_data] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Create an image plot\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "img = ax.imshow(b4_data_classified, extent=b4_data_extent)\n",
    "fig.colorbar(img, values=[10, 20, 30], ticks=[10, 20, 30])\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "The data sets `./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff` and `./data/gent/raster/2020-09-17_Sentinel_2_L1C_B08.tiff` contain respectively the 4th and the 8th band of a sentinel satellite image. To derive the [Normalized Difference Vegetation Index) (NDVI)](https://nl.wikipedia.org/wiki/Normalized_Difference_Vegetation_Index), the two bands need to be combined as follows:\n",
    "    \n",
    "$$\\frac{band_8 - band_4}{band_8 + band_4} $$\n",
    "    \n",
    "Process the images and create a plot of the NDVI:\n",
    "    \n",
    "- Read both data sets using Rasterio and store them in resp. `b4_data` and `b8_data`. \n",
    "- Combine both data sets using the `np.vstack` function and assign it to the variable `b48_bands`\n",
    "- Transform the data range of each of the layers to the range .0 - 1.\n",
    "- For the values equal to zero in the `b48_bands` data set, assign a new (very small) value 1e-6\n",
    "- Calculate the NDVI\n",
    "- Plot the NDVI and select an appropriate colormap.\n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* For more specific adjustments to the colormap, have a check on the [Matplotlib documentation on colormap normalization](https://matplotlib.org/3.3.2/tutorials/colors/colormapnorms.html)\n",
    "\n",
    "</details>   \n",
    "           \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "xr_b4_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "b4_data = xr_b4_data.data\n",
    "xr_b8_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B08.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "b8_data = xr_b8_data.data\n",
    "\n",
    "# Get extent\n",
    "(left, bottom, right, top) = xr_b4_data.rio.bounds()\n",
    "b4_data_extent = (left, right, bottom, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Combine both arrays by stacking them together\n",
    "b48_bands = np.vstack((b4_data, b8_data))  # 0 is b4 and 1 is b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b48_bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Rescale the data to 0-1\n",
    "b48_min = b48_bands.min(axis=(1, 2), keepdims=True)\n",
    "b48_max = b48_bands.max(axis=(1, 2), keepdims=True)\n",
    "b48_bands = ((b48_bands - b48_min)/(b48_max - b48_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Assign very small value to 0-values\n",
    "b48_bands[b48_bands == 0] = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the ndvi using the stacked data\n",
    "ndvi = (b48_bands[1] - b48_bands[0])/(b48_bands[0] + b48_bands[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "clear_cell": false
   },
   "source": [
    "Using a Matplotlib norm to adjust colormap influence on image https://matplotlib.org/api/_as_gen/matplotlib.colors.TwoSlopeNorm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# A Sequential colormap `YlGn` with a normalization on the color limits\n",
    "import matplotlib.colors as mcolors\n",
    "div_norm = mcolors.Normalize(0.1, 0.8)\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ll = ax.imshow(ndvi, cmap=\"YlGn\", extent=b4_data_extent, norm=div_norm)\n",
    "fig.colorbar(ll);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# A Diverging colormap `RdYlGn` with a normalization on the color limits in two directions of the central point:\n",
    "div_norm = mcolors.TwoSlopeNorm(vmin=-0.1, vcenter=0.4, vmax=0.8)\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ll = ax.imshow(ndvi, cmap=\"RdYlGn\", extent=b4_data_extent, norm=div_norm)\n",
    "fig.colorbar(ll);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## For the curious: Some more building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy provides lower-level building blocks used by other packages and you will once in a also need to rely on these functions to do some custom implementation. Some other useful building blocks with repect to reclassification could potentially help you:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember the `np.where` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy = np.arange(1, 10).reshape(3, 3)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.where(dummy > 4, 0, dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clip the values in yanour array to defined limits can be done using `np.clip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy = np.arange(1, 10).reshape(3, 3)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.clip(dummy, 2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numpy provides also a `np.histogram` function, which is really useful to get the bincounts over a custom bin-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.histogram(b4_data_classified, bins=[5, 15, 25, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.histogram(b4_data, bins=[0.001, 0.1, 0.2, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `np.digitize` function return the indices of the bins to which each value in input array belongs. As such, it can be used to select and manipulate values containing to a specific bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy = np.arange(9).reshape(3, 3)\n",
    "np.random.shuffle(dummy)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the bin to which each of the values belong to, using the bins x<2, 2<=x<4, x>=4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "id_mask = np.digitize(dummy, bins=[2, 4])\n",
    "id_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dummy[id_mask == 1] = 20\n",
    "dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, it is also a practical method to create discrete classified maps:\n",
    "\n",
    "  1. Apply digitize to create classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_class_bins = [-np.inf, 0, 0.3, np.inf]  # These limits are for demo purposes only \n",
    "ndvi_landsat_class = np.digitize(ndvi, ndvi_class_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. Define custom colors and names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_colors = [\"gray\", \"yellowgreen\", \"g\"]\n",
    "ndvi_names = [\"No Vegetation\", \"Bare Area\", \"Vegetation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. Prepare Matplotlib elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_cmap = ListedColormap(nbr_colors)\n",
    "# fake entries required for each class to create the legend\n",
    "dummy_data = [Line2D([0], [0], color=color, lw=4) for color in nbr_colors]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  4. Make the plot and add a legend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "im = ax.imshow(ndvi_landsat_class, cmap=nbr_cmap, extent=b4_data_extent)\n",
    "ax.legend(dummy_data, ndvi_names, loc='upper left', framealpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the modal (most common) value in an array is not provided by Numpy itself, but is available in the Scipy package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mode(b4_data.flatten()), mode(b4_data_classified.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-note on convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need custom convolutions for your 2D array, check the `scipy.signal.convolve` function as the Numpy function only works for 1-D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_b4_data = xr.open_dataarray(\"./data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", \n",
    "                               engine=\"rasterio\", mask_and_scale=False)\n",
    "b4_data = xr_b4_data.data\n",
    "\n",
    "# Get extent\n",
    "(left, bottom, right, top) = xr_b4_data.rio.bounds()\n",
    "b4_data_extent = (left, right, bottom, top)\n",
    "\n",
    "b4_data = b4_data.squeeze().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, apply a low pass filter example as window, smoothing the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "window = np.ones((5, 5), dtype=int)\n",
    "window[1:-1, 1:-1] = 4\n",
    "window[2, 2] = 12\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = signal.convolve(b4_data, window, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "ax0.imshow(b4_data, extent=b4_data_extent)\n",
    "ax1.imshow(grad, extent=b4_data_extent)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Nbtutor - export exercises",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
