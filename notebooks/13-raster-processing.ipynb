{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=\"6\"><b> Raster operations and raster-vector tools</b></font></p>\n",
    "\n",
    "\n",
    "> *DS Python for GIS and Geoscience*  \n",
    "> *November, 2022*\n",
    ">\n",
    "> *Â© 2022, Joris Van den Bossche and Stijn Van Hoey. Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the previous notebooks, we focused either on vector data or raster data. Often you encounter both types of data and want to combine them. In this notebook, we show *some* examples of typical raster/vector interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import rasterio\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `rioxarray`: xarray extension based on rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks, we already used `rasterio` (https://rasterio.readthedocs.io/en/latest/) to read raster files such as GeoTIFFs (through the `xarray.open_dataarray(...,engine=\"rasterio\")` function). Rasterio provides support for reading and writing geospatial raster data as numpy N-D arrays, mainly through bindings to the GDAL library. \n",
    "\n",
    "In addition, rasterio provides a Python API to perform some GIS raster operations (clip, mask, warp, merge, transformation,...) and can be used to only load a subset of a large dataset into memory. However, the main complexity in using `rasterio`, is that the spatial information is decoupled from the data itself (i.e. the numpy array). This means that you need to keep track and organize the extent and metadata throughout the operations (e.g. the \"transform\") and you need to keep track of what each dimension represents (y-first, as arrays are organized along rows first). Notebook [91_package_rasterio](./91_package_rasterio.ipynb) goes into more depth on the rasterio package itself. \n",
    "\n",
    "Enter `rioxarray` (https://corteva.github.io/rioxarray/stable/index.html), which extends xarray with geospatial functionalities powered by rasterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./data/herstappe/raster/2020-09-17_Sentinel_2_L1C_True_color.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rioxarray.open_rasterio(data_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rioxarray.open_rasterio` function is similar to `xarray.open_dataarray`.\n",
    "\n",
    "Once `rioxarray` is imported, it provides a `.rio` accessor on the xarray.DataArray object, which gives access to some properties of the raster data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.resolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprojecting rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rioxarray` gives access to a set of raster processing functions from rasterio/GDAL. \n",
    "\n",
    "One of those is to reproject (transform and resample) rasters, for example to reproject to different coordinate reference system, up/downsample to a different resolution, etc. In all those case, in the transformation of a source raster to a destination raster, pixel values need to be recalculated. There are different \"resampling\" methods this can be done: taking the nearest pixel value, calculating the average, a (non-)linear interpolation, etc.\n",
    "\n",
    "The functionality is available through the `reproject()` method. Let's start with reprojecting the Herstappe tiff to a different CRS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.reproject(\"EPSG:31370\").plot.imshow(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default resampling method is \"nearest\", which is often not a suitable method (especially for continuous data). We can change the method using the `rasterio.enums.Resampling` enumeration (see [docs](https://rasterio.readthedocs.io/en/latest/api/rasterio.enums.html#rasterio.enums.Resampling) for a overview of all methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.reproject(\"EPSG:31370\", resampling=Resampling.bilinear).plot.imshow(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method can also be used to downsample at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rio.reproject(data.rio.crs, resolution=120, resampling=Resampling.cubic).plot.imshow(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the data you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many applications, a specific research area is used. Extracting the data you need from a given raster data set by a vector (polygon) file is a common operation in GIS analysis. We use the clipping example to explain the typical workflow with rioxarray / rasterio.\n",
    "\n",
    "For our Herstappe example, the study area is available as vector data `./data/herstappe/vector/herstappe.geojson`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "herstappe_vect = geopandas.read_file(\"./data/herstappe/vector/herstappe.geojson\")\n",
    "herstappe_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "herstappe_vect.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "herstappe_vect.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure both data sets are defined in the same CRS and extracting the geometry can be used as input for the masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "herstappe_vect = herstappe_vect.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = data.rio.clip(herstappe_vect.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12,4))\n",
    "data.plot.imshow(ax=ax0)\n",
    "herstappe_vect.plot(ax=ax0, facecolor=\"none\", edgecolor=\"red\")\n",
    "\n",
    "clipped.plot.imshow(ax=ax1)\n",
    "herstappe_vect.plot(ax=ax1, facecolor=\"none\", edgecolor=\"red\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above uses the `rasterio` package (with the `mask` and `geometry_mask` / `rasterize` functionality) under the hood. This simplifies the operation compared to directly using `rasterio`.\n",
    "\n",
    "\n",
    "```python\n",
    "# cfr. The Rasterio workflow\n",
    "\n",
    "from rasterio.mask import mask\n",
    "\n",
    "# 1 - Open a data set using the context manager\n",
    "with rasterio.open(data_file) as src: \n",
    "\n",
    "    # 2 - Read and transform the data set by clipping\n",
    "    out_image, out_transform = mask(src, herstappe_vect.geometry, crop=True)\n",
    "    \n",
    "    # 3 - Update the spatial metadata/profile of the data set\n",
    "    herstappe_profile = src.profile\n",
    "    herstappe_profile.update({\"height\": out_image.shape[1],\n",
    "                              \"width\": out_image.shape[2],\n",
    "                              \"transform\": out_transform})\n",
    "    # 4 - Save the new data set with the updated metadata/profile                   \n",
    "    with rasterio.open(\"./herstappe_masked.tiff\", \"w\", **herstappe_profile) as dest: \n",
    "        dest.write(out_image)\n",
    "```\n",
    "\n",
    "The [91_package_rasterio](./91_package_rasterio.ipynb) notebook explains this workflow in more detail.\n",
    "\n",
    "One important difference, though, is that the above `rasterio` workflow will not load the full raster into memory when only loading (clipping) a small part of it. This can also be achieved in `rioxarray` with the `from_disk` keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert vector to raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DEM raster and river vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As example, we are using data from the Zwalm river area in Flanders. \n",
    "\n",
    "The digital elevation model (DEM) can be downloaded via the [governmental website](https://download.vlaanderen.be/Producten/Detail?id=936&title=Digitaal_Hoogtemodel_Vlaanderen_II_DSM_raster_5_m) ([download link](https://downloadagiv.blob.core.windows.net/dhm-vlaanderen-ii-dsm-raster-5m/DHMVIIDSMRAS5m_k30.zip), extracted in the `/data` directory for this example)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm_file = \"data/DHMVIIDSMRAS5m_k30/GeoTIFF/DHMVIIDSMRAS5m_k30.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Make sure you have downloaded the data set ([download link](https://downloadagiv.blob.core.windows.net/dhm-vlaanderen-ii-dsm-raster-5m/DHMVIIDSMRAS5m_k30.zip)), saved it in the `./data` subfolder and unzipped the folder_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm = xr.open_dataarray(dem_zwalm_file, engine=\"rasterio\").sel(band=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dem_zwalm.plot.imshow(\n",
    "    cmap=\"terrain\", figsize=(10, 4), interpolation='antialiased')\n",
    "img.axes.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we download the shapes of the rivers in the area through a WFS (Web Feature Service):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "wfs_rivers = \"https://geoservices.informatievlaanderen.be/overdrachtdiensten/VHAWaterlopen/wfs\"\n",
    "params = dict(service='WFS', version='1.1.0', request='GetFeature',\n",
    "              typeName='VHAWaterlopen:Wlas', outputFormat='json',\n",
    "              cql_filter=\"(VHAZONENR=460)OR(VHAZONENR=461)\", srs=\"31370\")\n",
    "\n",
    "# Fetch data from WFS using requests\n",
    "r = requests.get(wfs_rivers, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: A WFS is a standardized way to share vector GIS data sets on the internet, typically also used by web application, see ['A bit more about WFS'](#a_bit_more_about_WFS) section for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And convert the output of the wfs call to a GeoDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrame from geojson\n",
    "segments = geopandas.GeoDataFrame.from_features(json.loads(r.content), crs=\"epsg:31370\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.plot(figsize=(8, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip raster with vector\n",
    "\n",
    "The catchment extent is much smaller than the DEM file, so clipping the data first will make the computation less heavy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first download the catchment area of the Zwalm river from the Flemish government (using WFS again):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "wfs_bekkens = \"https://geoservices.informatievlaanderen.be/overdrachtdiensten/Watersystemen/wfs\"\n",
    "params = dict(service='WFS', version='1.1.0', request='GetFeature',\n",
    "              typeName='Watersystemen:WsDeelbek', outputFormat='json',\n",
    "              cql_filter=\"DEELBEKNM='Zwalm'\", srs=\"31370\")\n",
    "\n",
    "# Fetch data from WFS using requests\n",
    "r = requests.get(wfs_bekkens, params=params)\n",
    "catchment = geopandas.GeoDataFrame.from_features(json.loads(r.content), crs=\"epsg:31370\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to a file for later reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "catchment = catchment.to_crs('epsg:4326') # geojson is default 4326\n",
    "catchment.to_file(\"./data/zwalmbekken.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.read_file(\"./data/zwalmbekken.geojson\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using rioxarray (rasterio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we can use rioxarray to clip the raster file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm = xr.open_dataarray(dem_zwalm_file, engine=\"rasterio\").sel(band=1)\n",
    "dem_zwalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = dem_zwalm.rio.clip(catchment.to_crs('epsg:31370').geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using rioxarray's `to_raster()` method, we can also save the result to a new GeoTIFF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped.rio.to_raster(\"./dem_masked_rio.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DEM raster file used -9999 as the NODATA value, which are read as NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm.rio.nodata, clipped.rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = clipped.plot.imshow(\n",
    "    cmap='terrain', figsize=(10, 6), interpolation='antialiased')\n",
    "img.axes.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remmeber, with (rio)xarray, the conversion of nodata values to NaNs (and thus using float dtype) is done by default (`mask_and_scale`), but can be excluded using `mask_and_scale=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm2 = xr.open_dataarray(dem_zwalm_file, mask_and_scale=False).sel(band=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm2.rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm2.rio.clip(catchment.to_crs('epsg:31370').geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to avoid loading the full original raster data, the `from_disk` keyword can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_zwalm2.rio.clip(catchment.to_crs('epsg:31370').geometry, from_disk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using GDAL CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have the raster and vector files on disk, the [`gdal CLI`](https://gdal.org/programs/index.html) will be very fast to work with (note that GDAL automatically handles the CRS difference of the raster and vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm ./dem_masked_gdal.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalwarp -cutline ./data/zwalmbekken.geojson -crop_to_cutline data/DHMVIIDSMRAS5m_k30/GeoTIFF/DHMVIIDSMRAS5m_k30.tif ./dem_masked_gdal.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clipped_gdal = xr.open_dataarray(\"./dem_masked_gdal.tiff\", mask_and_scale=True).sel(band=1)\n",
    "img = clipped_gdal.plot.imshow(\n",
    "    cmap=\"terrain\", figsize=(10, 6), interpolation='antialiased')\n",
    "img.axes.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"font-size:120%\">\n",
    "\n",
    "**TIP**: <br>\n",
    "    \n",
    "In the GIS world, also other libraries do provide a large set of functionalities as command line instructions with a `FILE IN` -> `RUN COMMAND` -> `FILE OUT` approach, with some of them providing a Python interface as well. Some important once are:\n",
    "    \n",
    "- The [`gdal` library](https://gdal.org/programs/index.html#raster-programs) is the open source Swiss Army knife for raster and vector geospatial data handling. \n",
    "- The [SAGA GIS](http://www.saga-gis.org/en/index.html) has a [huge set](http://www.saga-gis.org/saga_tool_doc/8.0.0/a2z.html) of CLI commands, going from flow accumulation to classification algorithms.\n",
    "- The [WhiteboxTools](https://www.whiteboxgeo.com/geospatial-software/) is another example of a library with a lot of functionalities, e.g. hydrological, agricultural and terrain analysis tools.\n",
    "    \n",
    "Other important initiatives like [Grass](https://grasswiki.osgeo.org/wiki/GRASS-Wiki) and [PCRaster](https://pcraster.geo.uu.nl/) are worthwhile to check out. Most of these libraries of tools can also be used with QGIS.\n",
    "    \n",
    "__NOTE:__ You can run a CLI command inside a Jupyter Notebook by prefixing it with the `!` character.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert vector to raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a raster with the vector \"burned in\", we can use the `rasterio.features.rasterize` function. This expects a list of (shape, value) tuples, and an output image shape and transform. Here, we will create a new raster image with the same shape and extent as the DEM above. And we first take a buffer of the river lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_buffered = segments.geometry.buffer(100)\n",
    "img = rasterio.features.rasterize(\n",
    "    segments_buffered, \n",
    "    out_shape=clipped.shape, \n",
    "    transform=clipped.rio.transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(img)\n",
    "ax1.imshow(clipped.values - img*20, vmin=0, cmap=\"terrain\") # just as an example\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice!\n",
    "\n",
    "For these exercises, a set of raster and vector datasets for the region of Ghent is available. Throughout the exercises, the goal is to map preferential locations to live given a set of conditions (certain level above sea-level, quiet and green neighbourhood, ..).\n",
    "\n",
    "We start with the Digital Elevation Model (DEM) for Flanders. The data is available at https://overheid.vlaanderen.be/informatie-vlaanderen/producten-diensten/digitaal-hoogtemodel-dhmv, We downloaded the 25m resolution raster image, and provided a subset of this dataset as a zipped Tiff file in the course material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 1**:\n",
    "\n",
    "* Read the DEM using `xarray`. The zip file is available at `data/gent/DHMVIIDTMRAS25m.zip`. You can either unzip the file, and use the path to the unzipped file, or prepend `zip://` to the path. \n",
    "* What is the CRS of this dataset?\n",
    "* The dataset has a third dimension with a single band. This doesn't work for plotting, so create a new `DataArray` by selecting the single band. Assign the result to a variable `dem`.\n",
    "* Make a quick plot of the dataset.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* Rasterio can directly read from a zip-file. If one wants read the file `./data/gent/FILENAME.zip`, add the `zip://.data/gent/FILENAME.zip` to read the zip file directly.\n",
    "* The `crs` is an attribute, not a function, so no `()` required.\n",
    "* Selecting in xarray is done with `sel`\n",
    "* We will improve the plot in the following exercises, but as a quick solution, we already learnt about the `robust=True` plot option of xarray. \n",
    "* Just pick a color map that you like.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 2**:\n",
    "\n",
    "The dataset uses a large negative value to denote the \"nodata\" value (in this case meaning \"outside of Flanders\"). The nodata value is - by default - read by xarray as `np.nan`, but this behaviour can be excluded:\n",
    "    \n",
    "* Read the `zip://./data/gent/DHMVIIDTMRAS25m.zip\"` file (band=1) without converting the nodata value to `np.nan` (keep -9999.).\n",
    "* Check the value -9999. is used as \"nodata\" value.\n",
    "* Repeat the plot from the previous exercise, but now set a fixed minimum value of 0 for the colorbar, to ignore the negative \"nodata\" in the color scheme.\n",
    "* Replace the \"nodata\" value with `np.nan` using the `where()` method. \n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* The `nodata` attribute is provided by the rioxarray package. Rioxarray loads this information from the geotiff file metadata and makes it available as `.rio.nodata`. \n",
    "* The `.rio.nodata` is a class attribute, not a function, so no `()` required.\n",
    "* `vmin` and `vmax` define the colormap limits.\n",
    "* `áºhere` expects a condition (i.e. boolean values), e.g. `... != dem.rio.nodata`.\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing8.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember__ Alternatively to masking the nodata value manually, you can do this explicitly when loading the data, using the `mask_and_scale=True` keyword (see also notebook [11-xarray-intro.ipynb](11-xarray-intro.ipynb)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_masked = xr.open_dataarray(\"zip://./data/gent/DHMVIIDTMRAS25m.zip\", engine=\"rasterio\", mask_and_scale=True).sel(band=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_masked.plot.imshow(robust=True, cmap=\"terrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 3**:\n",
    "\n",
    "We want to limit our search for locations to the surroundings of the centre of Ghent.\n",
    "\n",
    "* Create a `Point` object for the centre of Ghent. Latitude/longitude coordinates for the Korenmarkt are: 51.05393, 3.72174\n",
    "* We need our point in the same Coordinate Reference System as the DEM raster (i.e. EPSG:31370, or Belgian Lambert 72). Use GeoPandas to reproject the point:\n",
    "    * Create a GeoSeries with this single point and specify its CRS with the `crs` keyword.\n",
    "    * Reproject this series with the `to_crs` method. Assign the resulting GeoSeries to a variable `gent_centre_31370`.\n",
    "* Calculcate a buffer of 10km radius around the point.\n",
    "* Get the bounding box coordinates of this buffer. Assign this to `gent_bounds`.\n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* Remember the introduction on geospatial data and the shapely objects, e.g. `shapely.geometry.Point`?\n",
    "* Use `geopandas.GeoSeries` to create a new GeoSeries and add the `crs` parameter. The lat/lon of the Kornmarkt are provided as EPSG:4326. \n",
    "* In EPSG:31370, the unit is meter, so make sure to use meter to define the buffer size.\n",
    "* `.total_bounds` is a class attribute.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing9.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing11.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing12.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 4**:\n",
    "\n",
    "With this bounding box, we can now clip a subset of the DEM raster for the area of interest. \n",
    "    \n",
    "* Clip the `dem` raster layer. To clip with a bounding box instead of a geometry, you can use the `rio.clip_box()` method instead of `rio.clip()`.\n",
    "* Make a plot. Use the \"terrain\" color map, and set the bounds of the color scale to 0 - 30.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* The `gent_bounds` is an array of 4 elements, whereas `clip_box` requires these as seperate input parameters... Did you know that in Python you can unpack these 4 values with the `*`: `*gent_bounds` will unpack to 4 individual input.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing13.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing14.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CORINE Land Cover (https://land.copernicus.eu/pan-european/corine-land-cover) is a program by the European Environment Agency (EEA) to provide an inventory of land cover in 44 classes of the European Union. The data is provided in both raster as vector format and with a resolution of 100m.\n",
    "\n",
    "The data for the whole of Europe can be downloaded from the website (latest version: https://land.copernicus.eu/pan-european/corine-land-cover/clc2018?tab=download). This is however a large dataset, so we downloaded the raster file and cropped it to cover Flanders, and this subset is included in the repo as `data/CLC2018_V2020_20u1_flanders.tif` (the code to do this cropping can be see at [data/preprocess_data.ipynb#CORINE-Land-Cover](data/preprocess_data.ipynb#CORINE-Land-Cover))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 5**:\n",
    "\n",
    "* Read the land use data provided as a tif (`data/CLC2018_V2020_20u1_flanders.tif`). Directly select the single band.\n",
    "* Make a quick plot. The raster is using a negative value as \"nodata\", consider using the `robust=True` option.\n",
    "* What is the resolution of this raster?\n",
    "* What is the CRS?\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* `rio.resolution()` is a method, so it requires the `()`.\n",
    "* `rio.crs` is an attribute, so it does not require the `()`.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing15.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing17.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing18.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 6**:\n",
    "\n",
    "The land use dataset is a European dataset and uses a Europe-wide projected CRS (https://epsg.io/3035).\n",
    "\n",
    "* Reproject the land use raster to the same CRS as the DEM raster (EPSG:31370), and plot the result.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* For the sake of the exercise, pick any resampling algorithm or just the default option.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing19.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing20.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 7**:\n",
    "\n",
    "In addition to reprojecting to a new CRS, we also want to upsample the land use dataset to the same resolution as the DEM raster, and to use the exact same grid layout, so we can compare and combine those rasters pixel-by-pixel.\n",
    "\n",
    "Such a reprojection can be done with the `reproject()` method by providing the target geospatial \"transform\" (which has the information for the bounds and resolution) and shape for the result. `rioxarray` provides a short-cut for this operation with the `reproject_match()` method, to reproject one raster to the CRS, extent and resolution of another raster.  \n",
    "\n",
    "* Reproject the land use raster to the same CRS and extent as the DEM subset for Ghent (`dem_gent`). Call the result `land_use_gent`.\n",
    "* Make a plot of the result.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* Check the help of the `.rio.reproject_match` method (SHIFT + TAB) to know which input ou need. For the sake of the exercise, pick any resampling algorithm or just the default (nearest) option.\n",
    "* The data calling the method is being transformed, and the input parameter is the target to match.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing21.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing22.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The land use dataset is a raster with discrete values (i.e. different land use classes). The [CurieuzeNeuzen case study](case-curieuzeneuzen-air-quality.ipynb#Combining-with-Land-Use-data) goes into more depth on those values, but for this exercise it is sufficient to know that values 1 and 2 are the Continuous and Discontinuous urban fabric (residential areas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 8**:\n",
    "\n",
    "Let's find the preferential locations to live, assuming we want to be future-proof and live at least 10m above sea level in a residential area.\n",
    "\n",
    "* Create a new array denoting the residential areas (where `land_use_gent` is equal to 1 or 2). Call this `land_use_residential`, and make a quick plot.\n",
    "* Plot those locations that are 10m above sea-level.\n",
    "* Combine the residential areas and areas > 10m in a single array called `suitable_locations`, and plot the result.\n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* To select for multiple options, one can either combine multiple conditions using `|` (or) or us the `isin([...,...])` option, both will do.\n",
    "* The output of a condition is a Boolean map that can be plot just like other maps, e.g. `(dem_gent > 10).plot.imshow()`.\n",
    "* Fo the `suitable_locations`, both boolean conditions need to be True, so combine them with either `&` or just multiply them with `*`.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing23.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing24.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing25.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing26.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing27.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing28.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 9**:\n",
    "\n",
    "In addition to the previous conditions, assume we also don't want to live close to major roads.\n",
    "\n",
    "We downloaded the road segments open data from Ghent (https://data.stad.gent/explore/dataset/wegsegmenten-gent/) as a GeoJSON file, and provided this in the course materials: `/data/gent/vector/wegsegmenten-gent.geojson.zip`\n",
    "    \n",
    "* Read the GeoJSON road segments file into a variable `roads` and check the first few rows.\n",
    "* The column \"frc_omschrijving\" contains a description of the type of road for each segment. Get an overview of the available segments and types by doing a \"value counts\" of this column.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* GeoPandas does NOT need the `zip://...` to read in zip files.\n",
    "* The first few rows are also the `head` of a data set.\n",
    "* The `value_counts` provides the number of records for each of the different values in a column.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing29.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing30.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing31.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 10**:\n",
    "\n",
    "We are interested in the big roads, as these are the ones we want to avoid: \"Motorway or Freeway\", \"Major Road\" and \"Other Major Road\".\n",
    "\n",
    "* Filter the `roads` table based on the provided list of road types: select those rows where the \"frc_omschrijving\" column is equal to one of those values, and call this `roads_subset`.\n",
    "* Make a quick plot of this subset and use the \"frc_omschrijving\" colum to color the lines.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* Selecting multiple options at the same time is most convenient with the `isin()` method.\n",
    "* Use the GeoPandas `.plot` method and specifh the `frc_omschrijving` column to the `column` parameter.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_types = [\n",
    "    \"Motorway, Freeway, or Other Major Road\",\n",
    "    \"a Major Road Less Important than a Motorway\",\n",
    "    \"Other Major Road\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing32.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing33.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 11**:\n",
    "\n",
    "Before we convert the vector data to a raster, we want to buffer the roads. We will use a larger buffer radius for the larger roads.\n",
    "\n",
    "* Using the defined `buffer_per_roadtype` dictionary, create a new Series by replacing the values in the \"frc_omschrijving\" column with the matching buffer radius.\n",
    "* Convert the `roads_subset` GeoDataFrame to CRS `EPSG:31370`, and create buffered lines (polygons) with the calculated buffer radius distances. Call the result `roads_buffer`.\n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* Use the `replace` method to replace the data using the provided mapping `buffer_per_roadtype`.\n",
    "* The conversion to EPSG:31370 is important to be able to work with the meters to define the buffer size.\n",
    "* The `buffer` method can take a single value to apply to all values, but also a Series of values, with a buffer size defined for each element.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_per_roadtype = {\n",
    "    \"Motorway, Freeway, or Other Major Road\": 750,\n",
    "    \"a Major Road Less Important than a Motorway\": 500,\n",
    "    \"Other Major Road\": 150,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing34.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing35.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 12**:\n",
    "\n",
    "Convert the buffered road segments to a raster:\n",
    "    \n",
    "* Use `features.features.rasterize()` to convert the `roads_buffer` GeoDataFrame to a raster:\n",
    "    * Pass the geometry column as the first argument.\n",
    "    * Pass the shape and transform of the `dem_gent` to specify the desired spatial extent and resolution of the output raster.\n",
    "* Invert the values of the raster by doing `1 - arr`, and plot the array with `plt.imshow(..)`.\n",
    "* Recalculate the `suitable_locations` variable, using 1/ land_use_residential, 2/ dem > 10 and 3/ outside the road buffers.  \n",
    "    \n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* Access the geometry column using the `.geometry` attribute.\n",
    "* `shape` is also an attribute.\n",
    "* `.rio.transform()` is a method, so it requires the `()`.\n",
    "* Previously, suitable locations were `land_use_residential * (dem_gent > 10)`. Combine this with the `(1 - roads_buffer_arr)` output.\n",
    "\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing36.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing37.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing38.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing39.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing40.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 13**:\n",
    "\n",
    "Make a plot with a background map of the selected locations. \n",
    "    \n",
    "* Plot the provided `gent` GeoDataFrame (a single row table with the are of the Ghent municipality). Use a low \"alpha\" to give it a light color.\n",
    "* Add a background map using contextily.\n",
    "* Plot the `suitable_locations` raster on top of this figure: first mask the array to select only those values larger than zero (so the other values becomes NaN, and are not plotted). Then plot the result, adding it to the existing figure using the `ax` keyword.\n",
    "\n",
    "<details><summary>Hints</summary>\n",
    "\n",
    "* The `fig, ax = plt.subplots(figsize=(15, 15))` is a convenient shortcut to prepare a Matplotlib Figure and Axes. \n",
    "* Make sure to define the `crs=\"EPSG:31370\"` for contextily.\n",
    "* `where(...)` is a powerfull way to exclude data as it - by default - adds NaN values for piels where the condition is not True.\n",
    "</details>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gent = geopandas.read_file(\"data/gent/vector/gent.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing41.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced (optional) exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 14**:\n",
    "\n",
    "We downloaded the data about urban green areas in Ghent (https://data.stad.gent/explore/dataset/parken-gent).\n",
    "\n",
    "* Read in the data at `data/gent/vector/parken-gent.geojson` into a variable `green`.\n",
    "* Check the content (first rows, quick plot)\n",
    "* Remove the rows with an empty geometry (`None`)    \n",
    "* Convert this vector layer to a raster using the spatial extent and resolution of `dem_gent` as the targer raster.\n",
    "* The `rasterio.features.rasterize` results in a numpy array. Convert this to a DataArray using the `xr.DataArray(..)` constructor, specifying the coordinates of `dem_gent` (`dem_gent.coords`) for the coordinates of the new array.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing42.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing43.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing44.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing45.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing46.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing47.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 15**:\n",
    "\n",
    "For the urban green areas, we want to calculate a statistic for a neighbourhood around each pixel (\"focal\" statistics). This can be expressed as a convolution with a defined kernel.    \n",
    "\n",
    "The [xarray-spatial](https://xarray-spatial.org/index.html) package includes functionality for such focal statistics and convolutions.\n",
    "\n",
    "* Use the `focal.focal_stats()` function from xarray-spatial to calculate the sum of green are in a neighborhood of 500m around each point. Check the help of this function to see which arguments to specify.\n",
    "* Make a plot of the resulting `green_area` array.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrspatial import focal, convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = convolution.calc_cellsize(green_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = convolution.circle_kernel(x, y, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing48.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing49.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scipy` package also provides optimized convolution algorithms. In case of the \"sum\" statistic, this is equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing50.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing51.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 16**:\n",
    "\n",
    "Make a plot with a background map of the selected locations, i.e. land_use_residential, dem > 10, outside road buffers and 'sufficient'as green area. \n",
    "    \n",
    "Define sufficient green area as the `green_area` pixels where the sum of the convolution (previous exercise) is larger as 10 (keep those values and convert pixels with values lower than 10 to 0 values). Multiply the different conditions/categories, so the green area score is included in the final result.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing52.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/13-raster-processing53.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gent = geopandas.read_file(\"data/gent/vector/gent.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gent.to_crs(\"EPSG:31370\").plot(ax=ax, alpha=0.1)\n",
    "ax.set(ylim=(190_000, 200_000), xlim=(100_000, 110_000))\n",
    "contextily.add_basemap(ax, crs=\"EPSG:31370\")\n",
    "\n",
    "suitable_locations.where(suitable_locations>0).plot.imshow(ax=ax, alpha=0.5, add_colorbar=False)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting values from rasters based on vector data\n",
    "\n",
    "The **rasterstats** package provides methods to calculate summary statistics of geospatial raster datasets based on vector geometries (https://github.com/perrygeo/python-rasterstats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this, we are reading a raster file with elevation data of the full world (the file contains a single band for the elevation, save the file in the `data` subdirectory; [download link](https://www.eea.europa.eu/data-and-maps/data/world-digital-elevation-model-etopo5/zipped-dem-geotiff-raster-geographic-tag-image-file-format-raster-data/zipped-dem-geotiff-raster-geographic-tag-image-file-format-raster-data/at_download/file)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = geopandas.read_file(\"./data/ne_110m_admin_0_countries.zip\")\n",
    "cities = geopandas.read_file(\"./data/ne_110m_populated_places.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_geotiff = \"data/DEM_geotiff/alwdgg.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = xr.open_dataarray(dem_geotiff).sel(band=1).plot.imshow(cmap=\"terrain\", figsize=(10, 4), )\n",
    "img.axes.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this raster of the elevation, we might want to know the elevation at a certain location or for each country.\n",
    "For the countries example, we want to extract the pixel values that fall within a country polygon, and calculate a statistic for it, such as the mean or the maximum.\n",
    "\n",
    "Such functionality to extract information from a raster for given vector data is provided by the rasterstats package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For extracting the pixel values for polygons, we use the `zonal_stats` function, passing it the GeoSeries, the path to the raster file, and the method to compute the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rasterstats.zonal_stats(countries.geometry, dem_geotiff,\n",
    "                                 stats=['min', 'mean', 'max'], \n",
    "                                 nodata=-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be assigned to new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[['min', 'max', 'mean']] = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can sort by the average elevation of the country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.sort_values('mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For points, a similar function called `point_query` can be used (specifying the interpolation method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"elevation\"] = rasterstats.point_query(cities.geometry, \n",
    "                                              dem_geotiff, interpolate='bilinear',\n",
    "                                              nodata=-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.sort_values(by=\"elevation\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "# A bit more about WFS\n",
    "\n",
    "> The Web Feature Service (WFS) represents a change in the way geographic information is created, modified and exchanged on the Internet. Rather than sharing geographic information at the file level using File Transfer Protocol (FTP), for example, the WFS offers direct fine-grained...\n",
    "\n",
    "(https://www.ogc.org/standards/wfs)\n",
    "\n",
    "In brief, the WFS is the specification to __access and download vector datasets__.\n",
    "\n",
    "To access WFS data, you need the following information:\n",
    "- URL of the service, e.g. `https://geoservices.informatievlaanderen.be/overdrachtdiensten/VHAWaterlopen/wfs`. Looking for these URLS, check [WFS page of Michel Stuyts](https://wfs.michelstuyts.be/?lang=en)\n",
    "- The available projections and layers, also check [WFS page of Michel Stuyts](https://wfs.michelstuyts.be/?lang=en) or start looking into the `GetCapabilities`, e.g. [vha waterlopen](https://geoservices.informatievlaanderen.be/overdrachtdiensten/VHAWaterlopen/wfs?REQUEST=GetCapabilities&SERVICE=WFS)\n",
    "\n",
    "Instead of downloading the entire data set, filtering the request itself (only downloading what you need) is a good idea, using the `cql_filter` filter. Finding out these is sometimes a bit of hazzle... E.g. quickly [preview the data in QGIS](https://docs.qgis.org/3.10/en/docs/training_manual/online_resources/wfs.html?highlight=wfs).\n",
    "\n",
    "You can also use the [`OWSLib` library](https://geopython.github.io/OWSLib/#wfs). But as WFS is a webservice, the `requests` package will be sufficient for simple queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example - municipalities in Belgium, see https://wfs.michelstuyts.be/service.php?id=140&lang=en, _WFS Voorlopig referentiebestand gemeentegrenzen 2019_\n",
    "\n",
    "- URL of the service: https://geoservices.informatievlaanderen.be/overdrachtdiensten/VRBG2019/wfs\n",
    "- Available projections:  EPSG:4258, EPSG:3812,...\n",
    "- Available layers: VRBG2019:Refgem:,  VRBG2019:Refarr:,...\n",
    "- Column `Naam` contains the municipatility, e.g. `Gent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs_municipality = \"https://geoservices.informatievlaanderen.be/overdrachtdiensten/VRBG2019/wfs\"\n",
    "params = dict(service='WFS', version='1.1.0', request='GetFeature',\n",
    "              typeName='VRBG2019:Refgem', outputFormat='json',\n",
    "              cql_filter=\"NAAM='Gent'\", srs=\"31370\")\n",
    "\n",
    "# Fetch data from WFS using requests\n",
    "r = requests.get(wfs_municipality, params=params)\n",
    "gent = geopandas.GeoDataFrame.from_features(json.loads(r.content), crs=\"epsg:31370\")\n",
    "gent.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud: only download what you need\n",
    "\n",
    "Rasterio/rioxarray only reads the data from disk that is requested to overcome loading entire data sets into memory. The same applies to downloading data, overcoming entire downloads when only a fraction is required (when the online resource supports this). An example is https://zenodo.org/record/2654620, which is available as [Cloud Optimized Geotiff (COG)](https://www.cogeo.org/). Also cloud providers (AWS, google,...) do support COG files, e.g. [Landstat images](https://docs.opendata.aws/landsat-pds/readme.html).\n",
    "\n",
    "These files are typically very large to download, whereas we might only need a small subset of the data. COG files support downloading a subset of the data you need using a masking approach.\n",
    "\n",
    "Let's use the Averbode nature reserve data as an example, available at the URL: http://s3-eu-west-1.amazonaws.com/lw-remote-sensing/cogeo/20160401_ABH_1_Ortho.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_cog_rgb = 'http://s3-eu-west-1.amazonaws.com/lw-remote-sensing/cogeo/20160401_ABH_1_Ortho.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the metadata, without downloading the data itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_data = rioxarray.open_rasterio(averbode_cog_rgb) # usage of rioxarray.open_rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the entire data set would be 37645*35405\\*4 pixels of 4 byte, so more or less 5.3 GByte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "37645*35405*4 / 1e9  # Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_data.size  / 1e9  # Gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we have a study area which is much smaller than the total extent of the available image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, bottom, right, top = averbode_data.rio.bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "averbode_study_area = geopandas.read_file(\"./data/averbode/study_area.geojson\")\n",
    "ax = averbode_study_area.plot();\n",
    "ax.set_xlim(left, right);\n",
    "ax.set_ylim(bottom, top);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of COG data, the data can sometimes be requested on different resolution levels when stored as such. So, to get a very broad overview of the data, we can request the coarsest resolution by resampling and download the data at the resampled resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(averbode_cog_rgb) as src:\n",
    "    # check available overviews for band 1\n",
    "    print(f\"Available resolutions are {src.overviews(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_64 = rioxarray.open_rasterio(averbode_cog_rgb, overview_level=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**REMEMBER**:\n",
    "\n",
    "`rioxarray.open_rasterio` is used here instead of `xr.open_dataarray(..., engine=\"rasterio\")` as the latter does not support the `overview_level` argument. In general, both should be comparable in behaviour.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_64.size / 1e6  # Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_64.rio.resolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the thumbnail version of the data with our study area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "averbode_64.sel(band=[1, 2, 3]).plot.imshow(ax=ax)\n",
    "averbode_study_area.plot(ax=ax, color='None', edgecolor='red', linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the entire data file would be overkill. Instead, we only want to download the data of the study area. This can be done with the `clip()` method using the `from_disk` option. \n",
    "The resulting data set will still be around 100MB and will take a bit of time to download, but this is only a fraction of the original data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Only run this cell when sufficient band width ;-)\n",
    "averbode_subset = averbode_data.rio.clip(averbode_study_area.geometry, from_disk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_subset.size / 1e6  # Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averbode_subset.sel(band=[1, 2, 3]).plot.imshow(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rasterio way:\n",
    "\n",
    "```python\n",
    "output_file = \"./averbode_orthophoto.tiff\"\n",
    "\n",
    "# Only run this cell when sufficient band width ;-)\n",
    "with rasterio.open(averbode_cog_rgb) as averbode_rgb:\n",
    "    averbode_rgb_image, averbode_rgb_transform = rasterio.mask.mask(averbode_rgb, averbode_study_area.geometry, crop=True)\n",
    "    averbode_rgb_profile = averbode_rgb.profile  \n",
    "\n",
    "    averbode_rgb_profile.update({\"driver\": \"GTiff\",\n",
    "                                 \"height\": averbode_rgb_image.shape[1],\n",
    "                                 \"width\": averbode_rgb_image.shape[2],\n",
    "                                 \"transform\": averbode_rgb_transform\n",
    "                                })\n",
    "    \n",
    "    with rasterio.open(output_file, \"w\", **averbode_rgb_profile) as dest:\n",
    "        dest.write(averbode_rgb_image)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to https://geohackweek.github.io/raster/04-workingwithrasters/ for the inspiration"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-run_control,-deletable,-editable,-jupyter,-slideshow"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
