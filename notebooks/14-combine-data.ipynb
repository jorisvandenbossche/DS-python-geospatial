{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32d4d6e-6b28-4ace-ad01-0f8c4465794c",
   "metadata": {},
   "source": [
    "<p><font size=\"6\"><b>Stacking of raster data</b></font></p>\n",
    "\n",
    "\n",
    "> *DS Python for GIS and Geoscience*  \n",
    "> *November, 2022*\n",
    ">\n",
    "> *© 2022, Joris Van den Bossche and Stijn Van Hoey. Licensed under [CC BY 4.0 Creative Commons](http://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40325d7c-ccb2-4c18-8a5f-98fb25383399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a4867-cc75-43c3-971e-df1e9991761e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563d475-a2c7-4914-8e4c-2bb5fe08d312",
   "metadata": {},
   "source": [
    "Geospatial time series data is often stored as multiple individual files. For example, remote sensing data or geoscience model output are typically organized with each time step (or band) in a separate file. Handling all these indidivudal files is culbersome and workflows to combine these files into a single `xarray.Dataset` or `xarray.DataArray` prior to the analysis are required. \n",
    "\n",
    "In this notebook, we will explore some ways to combine indidivual files into a single data product ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094477e-1610-4477-a6f9-25934dcb23b0",
   "metadata": {},
   "source": [
    "## Load multiple files into a single `xarray.Dataset/xarray.DataArray`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404fe62e-1aa6-4d0f-85bc-14ab660d248a",
   "metadata": {},
   "source": [
    "In some of the previous notebooks, we used the band 4 and band 8 Sentinel image data from Ghent, which are both stored as a separate data file in the `data` directory.\n",
    "\n",
    "One way to handle this is to load each of the data sets into memory and concatenate these afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a765a96-ef2e-47a9-b115-62012edad698",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_b4 = xr.open_dataarray(\"data/gent/raster/2020-09-17_Sentinel_2_L1C_B04.tiff\", engine=\"rasterio\")\n",
    "arr_b8 = xr.open_dataarray(\"data/gent/raster/2020-09-17_Sentinel_2_L1C_B08.tiff\", engine=\"rasterio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954ed80-d853-4786-9ed9-c72d2253c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_var = xr.Variable('band', [\"B4\", \"B8\"])\n",
    "arr = xr.concat([arr_b4, arr_b8], dim=band_var)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5345cdb-ca88-457b-9604-4b993995f5e3",
   "metadata": {},
   "source": [
    "From now on, the data is contained in a single `DataArray` to do further analysis. This approach works just fine for this limited set of data.\n",
    "\n",
    "However, when more files need to be processed, this becomes labor/code intensive and additional automation is required. Consider the following example data in the data folder `./data/herstappe/raster/sentinel_moisture/`:\n",
    "\n",
    "```\n",
    "./data/herstappe/raster/sentinel_moisture/\n",
    "├── 2016-05-01, Sentinel-2A L1C, Moisture index.tiff\n",
    "├── 2019-02-15, Sentinel-2A L1C, Moisture index.tiff\n",
    "└── 2020-02-07, Sentinel-2A L1C, Moisture index.tiff\n",
    "```\n",
    "\n",
    "It is a (small) extract of a time series of moisture index data derived from sentinel-2A, made available by [Sentinel-Hub](https://apps.sentinel-hub.com/eo-browser), a time series of remote sensing images. \n",
    "\n",
    "Instead of manually loading the data, we rather automate the data load from these files to a single xarray object:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f2f34-e7ce-4796-b2d9-15352c825ca8",
   "metadata": {},
   "source": [
    "1. Identify all files in the data folder and make a list of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e849f0bc-040f-4e46-b48e-5ff4cce481ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "moisture_index_files = list(sorted(Path(\"./data/herstappe/raster/sentinel_moisture\").rglob(\"*.tiff\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ef2f0-1b1e-440d-a4ef-108eed4911c6",
   "metadata": {},
   "source": [
    "2. Extract the time-dimension from each individual file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe7b26-993c-493e-b2ea-d566a6c5e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "moisture_index_dates = [pd.to_datetime(file_name.stem.split(\",\")[0]) for file_name in moisture_index_files]\n",
    "moisture_index_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd11d6-4543-4072-93ed-6cf647270071",
   "metadata": {},
   "source": [
    "__Note__ we use `pathlib` instead of `glob.glob` as it returns `Path` objects instead to represent the file names which are more powerful than regular strings returned by `glob.glob`, e.g. usage of `stem` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d1094-9593-4ae4-be5d-2b06b5d3d578",
   "metadata": {},
   "source": [
    "3.  Prepare an xarray variable which can be used as the additional date dimension/coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e68fe3-9378-4b11-a56f-ebe3168fdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_var = xr.Variable('date', moisture_index_dates)\n",
    "date_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d11cc-7d15-4bfa-8e6e-7b6aeafa157e",
   "metadata": {},
   "source": [
    "4. Load in and concatenate all individual GeoTIFFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d758c-bae3-4e7d-8308-fc5d16b37c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "moisture_index = xr.concat(\n",
    "    [xr.open_dataarray(file_name, engine=\"rasterio\", mask_and_scale=False) for file_name in moisture_index_files],\n",
    "    dim=date_var\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea6fae-e682-4694-ae2d-5f26ff267599",
   "metadata": {},
   "outputs": [],
   "source": [
    "moisture_index.sortby(\"date\").plot.imshow(col=\"date\", figsize=(15, 4), aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cabf74a-b9b5-472c-88b9-bf5e2e40deb2",
   "metadata": {},
   "source": [
    "## Lazy load multiple files into a single `xarray.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a3cbb-1ae5-4fec-94d8-ebc4d7604eab",
   "metadata": {},
   "source": [
    "In the previous example, all data is read into memory. Xarray provides a separate function [`open_mfdataset`](http://xarray.pydata.org/en/stable/generated/xarray.open_mfdataset.html#xarray-open-mfdataset) to read data lazy from disk (so not loading the data itself in memory) from multiple files. \n",
    "\n",
    "A usefule feature is the ability to preprocess the files:\n",
    "\n",
    "> __preprocess (callable(), optional)__ – If provided, call this function on each dataset prior to concatenation. You can find the file-name from which each dataset was loaded in ds.encoding[\"source\"].\n",
    "\n",
    "Applied to the previous moisture index files example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecb7b7-4a42-41ca-b79a-899cb9bf34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_dimension(ds):\n",
    "    \"\"\"Add the date dimension derived from the file_name and rename to moisture_index\"\"\"\n",
    "    ds_date = pd.to_datetime(Path(ds.encoding[\"source\"]).stem.split(\",\")[0])\n",
    "    ds = ds.assign_coords(date=(\"date\", [ds_date])).rename({\"band_data\": \"moisture_index\"})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf285fc6-e005-47b3-b1fa-8caa9b8eec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moisture_index_lazy = xr.open_mfdataset(sorted(Path(\"./data/herstappe/raster/sentinel_moisture\").rglob(\"*.tiff\")), \n",
    "                                        preprocess=add_date_dimension, engine=\"rasterio\", decode_cf=False) # parallel=True\n",
    "moisture_index_lazy[\"moisture_index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4684d-a762-4d90-a900-d97c77e3d775",
   "metadata": {},
   "source": [
    "The data itself is not loaded directly and is divided into 3 chunks, i.e. a chunk for each date. See the notebook [15-xarray-dask-big-data](./15-xarray-dask-big-data.ipynb) notebook for more information on the processing of (out of memory) lazy data with Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761309bb-ef60-4141-97ae-aa697c160001",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "\n",
    "- See http://xarray.pydata.org/en/stable/user-guide/io.html#reading-multi-file-datasets for more examples.\n",
    "- https://medium.com/@bonnefond.virginie/handling-multi-temporal-satellite-images-with-xarray-30d142d3391\n",
    "- https://docs.dea.ga.gov.au/notebooks/Frequently_used_code/Opening_GeoTIFFs_NetCDFs.html#Loading-multiple-files-into-a-single-xarray.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1046d9-8a09-46ec-967a-e0584d1113b7",
   "metadata": {},
   "source": [
    "## Save concatenated data to a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3559b-c79e-4e8b-971b-cb8074c6cc2d",
   "metadata": {},
   "source": [
    "After processing multiple files, it is convenient to save the data in a preferred format afterwards. Convenient choices are [NetCDF](https://www.unidata.ucar.edu/software/netcdf/) and [Zarr](https://zarr.readthedocs.io/en/stable/). Zarr is a newer format providing some advantages when working in cloud environments, but can be used on a local machine as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010efc3-fea9-4363-997a-39bff87cfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "moisture_index.to_netcdf(\"moisture_index_stacked.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde5d0f-56ee-4282-b28f-c27d5aa26ac1",
   "metadata": {},
   "source": [
    "Hence, the next the data set can be loaded directly from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc44dbd-5234-430e-9599-147d67321d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(\"moisture_index_stacked.nc\", engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165b475-b856-4c84-8464-8d9bf2f82315",
   "metadata": {},
   "source": [
    "Storing to zarr files works on the `xarray.DataSet` level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28bedfa-74cf-40c0-a295-c818e1675976",
   "metadata": {},
   "outputs": [],
   "source": [
    "moisture_index_lazy.to_zarr(\"moisture_index_stacked.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3b613-6d09-484a-8cc7-f0a7d8dba939",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(\"moisture_index_stacked.zarr\", engine=\"zarr\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b918bb6-1ff9-4503-9438-8cd81532e4b6",
   "metadata": {},
   "source": [
    "_clean up of these example files_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362f004-462b-4b4b-815e-d4bf12efd33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if Path(\"moisture_index_stacked.zarr\").exists():\n",
    "    shutil.rmtree(\"moisture_index_stacked.zarr\")\n",
    "if Path(\"moisture_index_stacked.nc\").exists():    \n",
    "    Path(\"moisture_index_stacked.nc\").unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8d675-e257-4af4-b2e3-cdcd4f070238",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**EXERCISE 1**:\n",
    "    \n",
    "The [NOAA's NCEP Reanalysis data](https://psl.noaa.gov/data/gridded/data.ncep.reanalysis.html) files are stored on a remote server and can be accessed over OpenDAP.\n",
    "    \n",
    "> The NCEP/NCAR Reanalysis data set is a continually updated (1948–present) globally gridded data set that represents the state of the Earth's atmosphere, incorporating observations and numerical weather prediction (NWP) model output from 1948 to present.\n",
    "    \n",
    "An example can be found in NCEP Reanalysis catalog:\n",
    "\n",
    "https://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/ncep.reanalysis/surface/catalog.html\n",
    "\n",
    "The dataset is split into different files for each variable and year. For example, a single file download link for surface air temperature looks like:\n",
    "\n",
    "https://psl.noaa.gov/thredds/fileServer/Datasets/ncep.reanalysis/surface/air.sig995.1948.nc   \n",
    "    \n",
    "The structure is `'http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.reanalysis/surface/air.sig995.`' + `'YYYY'` + `'.nc'`\n",
    "    \n",
    "We want to download the surface temperature data from 1990 till 2000 and combine them all in a single xarray DataSet. To do so:\n",
    "    \n",
    "- Prepare all the links by composing the base_url ('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.reanalysis/surface/air.sig995') with the required years\n",
    "- Use the list of file links as the inputfor the `xr.open_mfdataset` to create a single `xarray.DataSet`.\n",
    "- Whereas this is 600MB of data, the initial loading is not actually reading in the data.\n",
    "   \n",
    "<details>\n",
    "    \n",
    "<summary>Hints</summary>\n",
    "\n",
    "* Python works with string formatting, e.g. f'{base_url}.{year}.nc' will nicely create the required links.\n",
    "* Xarray can both work with file names on a computer as a compatible network link.\n",
    "* As the netcdf data provided by NOAA is already well structured and confomr, no further adjustments are required as input to the \n",
    "`open_mfdataset` function, :-)\n",
    "\n",
    "</details>    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8367c-644c-40eb-ad97-132183352142",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/14-combine-data1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26bd7e-4dbb-4e11-b721-30de58b38e5f",
   "metadata": {
    "tags": [
     "nbtutor-solution"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _solutions/14-combine-data2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee0d4d0-1c5d-47f9-9b51-cc458cc8c221",
   "metadata": {},
   "source": [
    "## (Optional) Online data Catalogs: STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e187b-9702-4d3b-9135-810cbe10e5f6",
   "metadata": {},
   "source": [
    "__Note__ _These dependencies are not included in the environment, to run this section, install the required packages first in your conda environment: `conda install stackstac pystac-client`._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc3a9c-9f5c-4fea-9037-c61593d9cb8f",
   "metadata": {},
   "source": [
    "Multiple initiatives do exist which publish data online which enables (lazy) loading of the data directly in xarray, such as [OpenDAP](https://www.opendap.org/) and [THREDDS](https://www.unidata.ucar.edu/software/tds/current/) which are well-known and used in the oceanographic and climate studies communities (see exercise). See for example the [ROMS Ocean Model Example](http://xarray.pydata.org/en/stable/examples/ROMS_ocean_model.html) tutorial of xarray. \n",
    "\n",
    "Another initiative that interacts well with xarray is the [SpatioTemporal Asset Catalogs](https://stacspec.org/) specification, which is increasingly used to publish remote sensing products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684349c7-1133-44a2-9164-2db4a0b5a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "import pystac_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6fdfd-03e0-4379-8dec-99a914969037",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon, lat = -105.78, 35.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7f65b-8c92-4b99-8298-979a28d6ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://earth-search.aws.element84.com/v0\"\n",
    "catalog = pystac_client.Client.open(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94265d-3f79-4ca8-a8ef-d1082355f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = catalog.search(\n",
    "    intersects=dict(type=\"Point\", coordinates=[lon, lat]),\n",
    "    collections=[\"sentinel-s2-l2a-cogs\"],\n",
    "    datetime=\"2020-04-01/2020-05-01\"\n",
    ")\n",
    "results.matched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c694b2a-6fc5-4501-927e-a3b725b08750",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(results.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be235744-2534-45c2-a1c6-b544ff42f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.item_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bcab24-e300-4392-ac0f-f5ed64273026",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = stackstac.stack(results.item_collection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394c52d-c3bd-4fa3-a9eb-b2a5e6fdd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640d68a-ecb7-4f21-b0b7-aea920ebdca6",
   "metadata": {},
   "source": [
    "See also https://github.com/stac-utils/pystac-client and https://stackstac.readthedocs.io/en/latest/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab0dbd-09cf-4eb0-be57-41a3b7d384cc",
   "metadata": {},
   "source": [
    "__Acknowledgements__ Thanks to [@rabernat](https://rabernat.github.io/research_computing_2018/xarray-tips-and-tricks.html) for the example case of NCEP reanalysis data load and https://stackstac.readthedocs.io/en/latest/basic.html#Basic-example for the stackteac example."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-run_control,-deletable,-editable,-jupyter,-slideshow"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
